
<!doctype html>
<html lang="zh" class="no-js">
  <head>
    
      <meta charset="utf-8">
      <meta name="viewport" content="width=device-width,initial-scale=1">
      
      
      
      
      
      
      <link rel="icon" href="../../../assets/avatar.png">
      <meta name="generator" content="mkdocs-1.5.3, mkdocs-material-9.4.6">
    
    
      
        <title>Foundations of Machine Learning - Matheart's Blog</title>
      
    
    
      <link rel="stylesheet" href="../../../assets/stylesheets/main.35e1ed30.min.css">
      
        
        <link rel="stylesheet" href="../../../assets/stylesheets/palette.356b1318.min.css">
      
      


    
    
      
    
    
      
        
        
        <link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
        <link rel="stylesheet" href="https://fonts.googleapis.com/css?family=JetBrains+Mono:300,300i,400,400i,700,700i%7CJetBrains+Mono:400,400i,700,700i&display=fallback">
        <style>:root{--md-text-font:"JetBrains Mono";--md-code-font:"JetBrains Mono"}</style>
      
    
    
      <link rel="stylesheet" href="https://gcore.jsdelivr.net/npm/katex@0.15.1/dist/katex.min.css">
    
      <link rel="stylesheet" href="https://gcore.jsdelivr.net/npm/lxgw-wenkai-screen-webfont@1.1.0/style.css">
    
      <link rel="stylesheet" href="https://gcore.jsdelivr.net/npm/lxgw-wenkai-webfont@1.1.0/style.css">
    
      <link rel="stylesheet" href="../../../css/tasklist.css">
    
      <link rel="stylesheet" href="../../../css/custom.css">
    
      <link rel="stylesheet" href="../../../css/card.css">
    
    <script>__md_scope=new URL("../../..",location),__md_hash=e=>[...e].reduce((e,_)=>(e<<5)-e+_.charCodeAt(0),0),__md_get=(e,_=localStorage,t=__md_scope)=>JSON.parse(_.getItem(t.pathname+"."+e)),__md_set=(e,_,t=localStorage,a=__md_scope)=>{try{t.setItem(a.pathname+"."+e,JSON.stringify(_))}catch(e){}}</script>
    
      

    
    
    
  </head>
  
  
    
    
      
    
    
    
    
    <body dir="ltr" data-md-color-scheme="slate" data-md-color-primary="indigo" data-md-color-accent="indigo">
  
    
    
      <script>var palette=__md_get("__palette");if(palette&&"object"==typeof palette.color)for(var key of Object.keys(palette.color))document.body.setAttribute("data-md-color-"+key,palette.color[key])</script>
    
    <input class="md-toggle" data-md-toggle="drawer" type="checkbox" id="__drawer" autocomplete="off">
    <input class="md-toggle" data-md-toggle="search" type="checkbox" id="__search" autocomplete="off">
    <label class="md-overlay" for="__drawer"></label>
    <div data-md-component="skip">
      
        
        <a href="#foundations-of-machine-learning" class="md-skip">
          跳转至
        </a>
      
    </div>
    <div data-md-component="announce">
      
    </div>
    
    
      

<header class="md-header" data-md-component="header">
  <nav class="md-header__inner md-grid" aria-label="页眉">
    <a href="../../.." title="Matheart&#39;s Blog" class="md-header__button md-logo" aria-label="Matheart's Blog" data-md-component="logo">
      
  <img src="../../../assets/avatar.png" alt="logo">

    </a>
    <label class="md-header__button md-icon" for="__drawer">
      
      <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M3 6h18v2H3V6m0 5h18v2H3v-2m0 5h18v2H3v-2Z"/></svg>
    </label>
    <div class="md-header__title" data-md-component="header-title">
      <div class="md-header__ellipsis">
        <div class="md-header__topic">
          <span class="md-ellipsis">
            Matheart's Blog
          </span>
        </div>
        <div class="md-header__topic" data-md-component="header-topic">
          <span class="md-ellipsis">
            
              Foundations of Machine Learning
            
          </span>
        </div>
      </div>
    </div>
    
      
        <form class="md-header__option" data-md-component="palette">
  
    
    
    
    <input class="md-option" data-md-color-media="" data-md-color-scheme="slate" data-md-color-primary="indigo" data-md-color-accent="indigo"  aria-hidden="true"  type="radio" name="__palette" id="__palette_1">
    
  
</form>
      
    
    
    
      <label class="md-header__button md-icon" for="__search">
        
        <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M9.5 3A6.5 6.5 0 0 1 16 9.5c0 1.61-.59 3.09-1.56 4.23l.27.27h.79l5 5-1.5 1.5-5-5v-.79l-.27-.27A6.516 6.516 0 0 1 9.5 16 6.5 6.5 0 0 1 3 9.5 6.5 6.5 0 0 1 9.5 3m0 2C7 5 5 7 5 9.5S7 14 9.5 14 14 12 14 9.5 12 5 9.5 5Z"/></svg>
      </label>
      <div class="md-search" data-md-component="search" role="dialog">
  <label class="md-search__overlay" for="__search"></label>
  <div class="md-search__inner" role="search">
    <form class="md-search__form" name="search">
      <input type="text" class="md-search__input" name="query" aria-label="搜索" placeholder="搜索" autocapitalize="off" autocorrect="off" autocomplete="off" spellcheck="false" data-md-component="search-query" required>
      <label class="md-search__icon md-icon" for="__search">
        
        <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M9.5 3A6.5 6.5 0 0 1 16 9.5c0 1.61-.59 3.09-1.56 4.23l.27.27h.79l5 5-1.5 1.5-5-5v-.79l-.27-.27A6.516 6.516 0 0 1 9.5 16 6.5 6.5 0 0 1 3 9.5 6.5 6.5 0 0 1 9.5 3m0 2C7 5 5 7 5 9.5S7 14 9.5 14 14 12 14 9.5 12 5 9.5 5Z"/></svg>
        
        <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M20 11v2H8l5.5 5.5-1.42 1.42L4.16 12l7.92-7.92L13.5 5.5 8 11h12Z"/></svg>
      </label>
      <nav class="md-search__options" aria-label="查找">
        
        <button type="reset" class="md-search__icon md-icon" title="清空当前内容" aria-label="清空当前内容" tabindex="-1">
          
          <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M19 6.41 17.59 5 12 10.59 6.41 5 5 6.41 10.59 12 5 17.59 6.41 19 12 13.41 17.59 19 19 17.59 13.41 12 19 6.41Z"/></svg>
        </button>
      </nav>
      
    </form>
    <div class="md-search__output">
      <div class="md-search__scrollwrap" data-md-scrollfix>
        <div class="md-search-result" data-md-component="search-result">
          <div class="md-search-result__meta">
            正在初始化搜索引擎
          </div>
          <ol class="md-search-result__list" role="presentation"></ol>
        </div>
      </div>
    </div>
  </div>
</div>
    
    
  </nav>
  
</header>
    
    <div class="md-container" data-md-component="container">
      
      
        
          
            
<nav class="md-tabs" aria-label="标签" data-md-component="tabs">
  <div class="md-grid">
    <ul class="md-tabs__list">
      
        
  
  
  
    
    
      <li class="md-tabs__item">
        <a href="../../.." class="md-tabs__link">
          
  
    
  
  Home

        </a>
      </li>
    
  

      
        
  
  
  
    
    
      <li class="md-tabs__item">
        <a href="../../../daily/update/" class="md-tabs__link">
          
  
    
  
  日常

        </a>
      </li>
    
  

      
        
  
  
  
    
    
      <li class="md-tabs__item">
        <a href="../../../academic/func_anal1/" class="md-tabs__link">
          
  
    
  
  学术

        </a>
      </li>
    
  

      
    </ul>
  </div>
</nav>
          
        
      
      <main class="md-main" data-md-component="main">
        <div class="md-main__inner md-grid">
          
            
              
              <div class="md-sidebar md-sidebar--primary" data-md-component="sidebar" data-md-type="navigation" >
                <div class="md-sidebar__scrollwrap">
                  <div class="md-sidebar__inner">
                    


  


<nav class="md-nav md-nav--primary md-nav--lifted" aria-label="导航栏" data-md-level="0">
  <label class="md-nav__title" for="__drawer">
    <a href="../../.." title="Matheart&#39;s Blog" class="md-nav__button md-logo" aria-label="Matheart's Blog" data-md-component="logo">
      
  <img src="../../../assets/avatar.png" alt="logo">

    </a>
    Matheart's Blog
  </label>
  
  <ul class="md-nav__list" data-md-scrollfix>
    
      
      
  
  
  
    
    
      
        
          
        
      
    
    
    
    
      
      
    
    <li class="md-nav__item md-nav__item--section md-nav__item--nested">
      
        
        
        
        <input class="md-nav__toggle md-toggle " type="checkbox" id="__nav_1" >
        
          
          
          <div class="md-nav__link md-nav__container">
            <a href="../../.." class="md-nav__link ">
              
  
  <span class="md-ellipsis">
    Home
  </span>
  

            </a>
            
          </div>
        
        <nav class="md-nav" data-md-level="1" aria-labelledby="__nav_1_label" aria-expanded="false">
          <label class="md-nav__title" for="__nav_1">
            <span class="md-nav__icon md-icon"></span>
            Home
          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
            
          </ul>
        </nav>
      
    </li>
  

    
      
      
  
  
  
    
    
      
        
      
        
      
        
      
        
      
        
      
    
    
    
    
      
      
    
    <li class="md-nav__item md-nav__item--section md-nav__item--nested">
      
        
        
        
        <input class="md-nav__toggle md-toggle " type="checkbox" id="__nav_2" >
        
          
          <label class="md-nav__link" for="__nav_2" id="__nav_2_label" tabindex="">
            
  
  <span class="md-ellipsis">
    日常
  </span>
  

            <span class="md-nav__icon md-icon"></span>
          </label>
        
        <nav class="md-nav" data-md-level="1" aria-labelledby="__nav_2_label" aria-expanded="false">
          <label class="md-nav__title" for="__nav_2">
            <span class="md-nav__icon md-icon"></span>
            日常
          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
                
  
  
  
    <li class="md-nav__item">
      <a href="../../../daily/update/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    一点小update
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
    <li class="md-nav__item">
      <a href="../../../daily/2023/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    2023年末的碎碎念
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
    <li class="md-nav__item">
      <a href="../../../daily/cpal.md" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    None
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
    <li class="md-nav__item">
      <a href="../../../daily/first_conf.md" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    None
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
    <li class="md-nav__item">
      <a href="../../../daily/before_exchange/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    写于交换前
  </span>
  

      </a>
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

    
      
      
  
  
  
    
    
      
        
      
        
      
    
    
    
    
      
      
    
    <li class="md-nav__item md-nav__item--section md-nav__item--nested">
      
        
        
        
        <input class="md-nav__toggle md-toggle " type="checkbox" id="__nav_3" >
        
          
          <label class="md-nav__link" for="__nav_3" id="__nav_3_label" tabindex="">
            
  
  <span class="md-ellipsis">
    学术
  </span>
  

            <span class="md-nav__icon md-icon"></span>
          </label>
        
        <nav class="md-nav" data-md-level="1" aria-labelledby="__nav_3_label" aria-expanded="false">
          <label class="md-nav__title" for="__nav_3">
            <span class="md-nav__icon md-icon"></span>
            学术
          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
                
  
  
  
    <li class="md-nav__item">
      <a href="../../../academic/func_anal1/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    泛函分析-无限维的线性代数（上）
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
    <li class="md-nav__item">
      <a href="../../../academic/acad_media/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    如何经营社交平台来获得更好的学术信息输入源
  </span>
  

      </a>
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

    
  </ul>
</nav>
                  </div>
                </div>
              </div>
            
            
              
              <div class="md-sidebar md-sidebar--secondary" data-md-component="sidebar" data-md-type="toc" >
                <div class="md-sidebar__scrollwrap">
                  <div class="md-sidebar__inner">
                    

<nav class="md-nav md-nav--secondary" aria-label="目录">
  
  
  
    
  
  
</nav>
                  </div>
                </div>
              </div>
            
          
          
            <div class="md-content" data-md-component="content">
              <article class="md-content__inner md-typeset">
                
                  


<h1 id="foundations-of-machine-learning">Foundations of Machine Learning<a class="headerlink" href="#foundations-of-machine-learning" title="Permanent link">&para;</a></h1>
<div class="admonition info">
<p class="admonition-title">Info</p>
<p>This book, <strong><em>Foundations of Machine Learning</em></strong>, serves as a general introduction to machine learning theory, it covers some basic tools of the field and also shows how to use the tools to justify and analyze the behevaior of machine learning algorithms.</p>
</div>
<h1 id="ch-2-the-pac-learning-framework">Ch 2 The PAC Learning Framework<a class="headerlink" href="#ch-2-the-pac-learning-framework" title="Permanent link">&para;</a></h1>
<div class="admonition introduction">
<p class="admonition-title">Introduction</p>
<p>PAC's full name is <strong>Probably Approximately Correct</strong>, this framework is mainly used to mathematically analyze the lower bound of the sample size, in order to achieve a certain high possibility while the error is small to some extent.</p>
</div>
<p>To present in a more formal way, we define <strong>concept</strong> as the mapping we are going to learn from <span class="arithmatex">\(\mathcal{X} \to \mathcal{Y}\)</span>. For example, concept can be the set of points inside a rectangle (which is a classical example we are going to show later), and the concept class <span class="arithmatex">\(C\)</span> is the set of concepts we wish to learn. We denote <span class="arithmatex">\(O(n)\)</span> as an u.b. on the cost of the computational representation of any element <span class="arithmatex">\(x \in \mathcal{X}\)</span>, and size(<span class="arithmatex">\(c\)</span>) as the maximal cost of the computational representation of <span class="arithmatex">\(c \in C\)</span>.</p>
<p>The learning problem is formulated as we have a <strong>hypothesis set</strong> <span class="arithmatex">\(H\)</span> and we pick <strong>hypothesis</strong> <span class="arithmatex">\(h\)</span> from it in order to approximate the ground truth concept (more formally, we say, <strong>target concept</strong>). Note that we always assume there is an underlying distribution <span class="arithmatex">\(D\)</span>, and the examples are <strong>independent and identically distributed (iid)</strong>, with this assumption, it is much easier for us to derive the theorems.</p>
<p>The hypothesis does not always exactly match the target concept, so there must be error, there are two types of error respectively, namely <strong>empirical error</strong> (<span class="arithmatex">\(\hat{R}(h)\)</span>), and <strong>generalization error</strong> (<span class="arithmatex">\(R(h)\)</span>). Empirical error can be accessed while the generalization errror is not directly accessible to the learner.</p>
<p>Given a hypothesis <span class="arithmatex">\(h \in H\)</span>, a target concept <span class="arithmatex">\(c \in C\)</span>, and an underlying distribution <span class="arithmatex">\(D\)</span>, then:</p>
<div class="arithmatex">\[\begin{align}
R(h) &amp;= \ \ \ \mathbb{E}_{x \sim D}{\  \mathbf{1}_{h(x) \neq c(x)}} = \text{Pr}_{x \sim D}{[h(x) \neq c(x)]}\\
\hat{R}(h) &amp;= \frac{1}{m}\sum_{i = 1}^{m}{\ \mathbf{1}_{h(x) \neq c(x)}}
\end{align}\]</div>
<p>With iid assumption we can prove that the expectation of empirical error is the generalization error.</p>
<h2 id="pac-learnable">PAC-Learnable<a class="headerlink" href="#pac-learnable" title="Permanent link">&para;</a></h2>
<div class="admonition definition">
<p class="admonition-title">Definition</p>
<p>A concept class <span class="arithmatex">\(C\)</span> is said to be <strong>PAC-learnable</strong> if there exists an algorithm <span class="arithmatex">\(\mathcal{A}\)</span> and a polynomial function poly <span class="arithmatex">\((\cdot, \cdot, \cdot, \cdot)\)</span> s.t. for any <span class="arithmatex">\(\varepsilon, \delta &gt; 0\)</span>, for all distributions <span class="arithmatex">\(D\)</span> on <span class="arithmatex">\(X\)</span> and for any target concept <span class="arithmatex">\(c \in C\)</span>, the following holds for any sample size <span class="arithmatex">\(m \geq\)</span> poly <span class="arithmatex">\((1/\varepsilon, 1/\delta, n, \text{size}(c))\)</span>:</p>
<div class="arithmatex">\[\text{Pr}_{S \sim D^m} [R(h_S) \leq \varepsilon] \geq 1 - \delta\]</div>
<p>It is called <strong>efficiently</strong> PAC-learnable if it further runs in poly <span class="arithmatex">\((1/\varepsilon, 1/\delta, n, \text{size}(c))\)</span>.</p>
</div>
<p>The intuition is that if the required sample size is not polynomial of those four "parameters" (for example it grows exponentially), in most practical case it is unrealistic to collect such amount of data.</p>
<p>Also note that this framework does not have any additional assumptions about underlying distribution, but both training and test samples should be drawn from the same distribution.</p>
<h2 id="classical-example-learning-axis-aligned-rectangles">Classical Example: Learning axis-aligned Rectangles<a class="headerlink" href="#classical-example-learning-axis-aligned-rectangles" title="Permanent link">&para;</a></h2>
<p>We would not elaborate the proof here but would highlight some of the key points. First is the algorithm <span class="arithmatex">\(\mathcal{A}\)</span> is to return the tightest rectangle containing all points with label 1 (denote as <span class="arithmatex">\(R_S\)</span>), s.t. there is no False-positives and there's only False-negatives (and they are contained in <span class="arithmatex">\(R\)</span>). </p>
<p>With such construction, we can safely assume Pr<span class="arithmatex">\([R] &gt; \varepsilon\)</span>, and construct four rectangles at the edge of <span class="arithmatex">\(R\)</span> respectively with each area exactly equal to <span class="arithmatex">\(\varepsilon/4\)</span>. We could show that if <span class="arithmatex">\(R_S\)</span> meets all four small rectangles, the error area <span class="arithmatex">\(\leq \varepsilon\)</span>. Its contraposition shows it must miss one of the small rectangle, the remaining part is just to derive probability inequality regarding <span class="arithmatex">\(\text{Pr}_{S \sim D^m}[\text{R}(R_S) &gt; \varepsilon]\)</span>, set <span class="arithmatex">\(\delta\)</span> equal to the upper bound of it, then we can finally derive the lower bound of <span class="arithmatex">\(m\)</span> i.e. <span class="arithmatex">\(\frac{4}{\varepsilon}\log \frac{4}{\delta}\)</span>. We know that <span class="arithmatex">\(n, \text{size}(c)\)</span> is constant, so it is PAC-learnable.</p>
<p>Such way of proof can be extended to more interesting problems (exercises in book), such as extending this result from <span class="arithmatex">\(\mathbb{R}^2\)</span> to <span class="arithmatex">\(\mathbb{R}^n\)</span>, learning concentric circles / triangles instead of rectangles, learn with noise etc.</p>
<h2 id="guarantees-for-finite-hypothesis-sets">Guarantees for finite hypothesis sets<a class="headerlink" href="#guarantees-for-finite-hypothesis-sets" title="Permanent link">&para;</a></h2>
<p>We extend the example above to more general settings, it is actually <strong>consistent</strong> i.e. the empirical error is 0 on training sample. In order to derive the bound more easily we need to assume that the hypothesis set is of finite size.</p>
<h3 id="consistent-case">Consistent case<a class="headerlink" href="#consistent-case" title="Permanent link">&para;</a></h3>
<div class="admonition theorem">
<p class="admonition-title">Theorem</p>
<p>Let <span class="arithmatex">\(H\)</span> be a finite set of functions mapping from <span class="arithmatex">\(\mathcal{X}\)</span> to <span class="arithmatex">\(\mathcal{Y}\)</span>. Let <span class="arithmatex">\(\mathcal{A}\)</span> be an algorithm that for any target concept <strong><span class="arithmatex">\(c \in H\)</span></strong> and i.i.d. sample <span class="arithmatex">\(S\)</span> returns a consistent hypothesis <span class="arithmatex">\(h_S: \hat{R}(h_S) = 0\)</span>. Then for any <span class="arithmatex">\(\varepsilon, \delta &gt; 0\)</span>, the inequality <span class="arithmatex">\(\text{Pr}_{S \sim D^m}[R(h_S) \leq \varepsilon] \geq 1 - \delta\)</span> holds if:</p>
<div class="arithmatex">\[m \geq \frac{1}{\varepsilon}(\log |H| + \log \frac{1}{\delta})\]</div>
<p>Another equivalent statement is that for any <span class="arithmatex">\(\varepsilon, \delta &gt; 0\)</span>, with probability at least <span class="arithmatex">\(1 - \delta\)</span>, we have</p>
<div class="arithmatex">\[R(h_S) \leq \frac{1}{m}(\log |H| + \log \frac{1}{\delta})\]</div>
</div>
<p>Want: We don't know what will be the <span class="arithmatex">\(h_S\)</span>, so we need to give an uniform convergence bound, bound Pr[<span class="arithmatex">\(\exists h \in H : \hat{R}(h) = 0 \text{ and } R(h) &gt; \varepsilon\)</span>] by <span class="arithmatex">\(\delta\)</span>.</p>
<p>Trivially we know the set is equal to the union of all hypothesis <span class="arithmatex">\(h\)</span> that has <span class="arithmatex">\(\hat{R}(h) = 0 \text{ and } R(h) &gt; \varepsilon\)</span>, so by union bound, it is bounded by <span class="arithmatex">\(\sum_{h \in H}{\text{Pr}[\hat{R}(h) = 0 \text{ and } R(h) &gt; \varepsilon]}\)</span>, this is further bounded by the conditional probability <span class="arithmatex">\(\sum_{h \in H}{\text{Pr}[\hat{R}(h) = 0 | R(h) &gt; \varepsilon]}\)</span>.</p>
<p>For each <span class="arithmatex">\(h\)</span> we are able to bound that by <span class="arithmatex">\((1 - \varepsilon)^m\)</span> by making use of definition of <span class="arithmatex">\(R(h)\)</span> and also i.i.d. property, this gives us the overall value is bounded by <span class="arithmatex">\(|H|(1 - \varepsilon)^m \leq |H| e^{-\varepsilon m}\)</span>.</p>
<p>When <span class="arithmatex">\(m \geq \frac{1}{\varepsilon}(\log |H| + \log \frac{1}{\varepsilon})\)</span>, with some simple algebraic manipulation we can obtain <span class="arithmatex">\(|H| e^{-\varepsilon m} \leq \delta\)</span>, this concludes the proof.    <span class="arithmatex">\(\square\)</span></p>
<p>The second statement shows that when the training sample size <span class="arithmatex">\(m\)</span> increases, the upper bound of generalization error will be tighter, this theoretically justifies learning algorithms benefit from larger labeled training samples. However, the price to pay for coming up with a consistent algorithm is the use of a larger hypothesis set <span class="arithmatex">\(H\)</span> containing target concepts, the upper bound invreases with <span class="arithmatex">\(|H|\)</span> but the dependency is only logarithmic.</p>
<h4 id="some-examples">Some examples<a class="headerlink" href="#some-examples" title="Permanent link">&para;</a></h4>
<p><strong>Conjunction of Boolean literals</strong>: <span class="arithmatex">\(|H|\)</span> is <span class="arithmatex">\(3^n\)</span> which is finite, we can also carry out a consistent algorithm, which means this is suitable for the theorem above. We can show <span class="arithmatex">\(m \geq ((\log 3)n + \log \frac{1}{\delta})\)</span></p>
<p><strong>Universal Concept Class</strong>: To guarantee a consistent hypothesis, <span class="arithmatex">\(|H| \geq |U_n| = 2^{(2^n)}\)</span>, this gives us the sample complexity bound <span class="arithmatex">\(m \geq \frac{1}{\varepsilon}((\log 2) 2^n + \log \frac{1}{\delta})\)</span>, this is actually not a polynomial, so it is not PAC-learnable.</p>
<p><strong>k-term DNF formulae</strong>: <span class="arithmatex">\(m \geq \frac{1}{\varepsilon}((\log 3)nk + \log \frac{1}{\delta})\)</span>. However, it is shown that this problem is <strong>RP</strong>, it is PAC-learnable but not efficient unless <strong>RP = NP</strong>.</p>
<p><strong>k-CNF formulae</strong>: We can reduce the formula into conjection of boolean literals by a bijection, so this implies the PAC-learanability of <strong>K-CNF formula</strong>. However, although DNF formula can be rewritten into K-CNF formula, itself is still not PAC-learnable. This is beacause the number of new variables needed for this transformation is in <span class="arithmatex">\(O(n^k)\)</span>. <strong>This apparent paradox deals with key aspects of PAC-learning, which include the cost of the representation of the concept and the choice of the hypothesis set</strong>.</p>
<h3 id="inconsistent-case">Inconsistent Case<a class="headerlink" href="#inconsistent-case" title="Permanent link">&para;</a></h3>
<p>In practice, <span class="arithmatex">\(H\)</span> may not contain the hypothesis consistent with the training sample, but inconsistent hypothesis with small number of errors on number of training samples is still useful. <strong>Hoeffding's inequality</strong> will be used to relate the generalization error and empirical error of a single hypothesis.</p>
<h1 id="ch-3-rademacher-complexity-and-vc-dimensions">Ch 3 Rademacher Complexity and VC-dimensions<a class="headerlink" href="#ch-3-rademacher-complexity-and-vc-dimensions" title="Permanent link">&para;</a></h1>
<div class="admonition introduction">
<p class="admonition-title">Introduction</p>
<p>We deal with the infinite hypothesis size in this chapter, we can use various techniques to reduce it into finite sets of hypotheses can proceed as in the previous chapter. Using <strong>Rademacher Complexity</strong> based on <strong>McDiarmid's inequality</strong> can derive high-quality bounds. However, the computation of empirical Rademacher complexity is NP-hard for some hypothesis sets. So we will introduce the <strong>growth function</strong> and <strong>VC-dimension</strong> which is easier to compute.</p>
</div>
<p>Formally any loss function <span class="arithmatex">\(L\)</span> is <span class="arithmatex">\(\mathcal{Y} \times \mathcal{Y} \to \mathbb{R}\)</span>, we use <span class="arithmatex">\(G\)</span> to denote family of loss functions associated to <span class="arithmatex">\(H\)</span>, </p>

  <hr>
<div class="md-source-file">
  <small>
    
      最后更新:
      <span class="git-revision-date-localized-plugin git-revision-date-localized-plugin-datetime">2023年12月31日 18:05:17</span>
      
    
  </small>
</div>




<!--  -->
                
              </article>
            </div>
          
          
        </div>
        
          <button type="button" class="md-top md-icon" data-md-component="top" hidden>
  
  <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M13 20h-2V8l-5.5 5.5-1.42-1.42L12 4.16l7.92 7.92-1.42 1.42L13 8v12Z"/></svg>
  回到页面顶部
</button>
        
      </main>
      
        <footer class="md-footer">
  
  <div class="md-footer-meta md-typeset">
    <div class="md-footer-meta__inner md-grid">
      <div class="md-copyright">
  
    <div class="md-copyright__highlight">
      Copyright &copy; 2022 - 2025 數心 (Matheart)
    </div>
  
  
    Made with
    <a href="https://squidfunk.github.io/mkdocs-material/" target="_blank" rel="noopener">
      Material for MkDocs
    </a>
  
</div>
      
    </div>
  </div>
</footer>
      
    </div>
    <div class="md-dialog" data-md-component="dialog">
      <div class="md-dialog__inner md-typeset"></div>
    </div>
    
    
    <script id="__config" type="application/json">{"base": "../../..", "features": ["content.code.annotate", "navigation.tracking", "navigation.tabs", "navigation.indexes", "navigation.top"], "search": "../../../assets/javascripts/workers/search.f886a092.min.js", "translations": {"clipboard.copied": "\u5df2\u590d\u5236", "clipboard.copy": "\u590d\u5236", "search.result.more.one": "\u5728\u8be5\u9875\u4e0a\u8fd8\u6709 1 \u4e2a\u7b26\u5408\u6761\u4ef6\u7684\u7ed3\u679c", "search.result.more.other": "\u5728\u8be5\u9875\u4e0a\u8fd8\u6709 # \u4e2a\u7b26\u5408\u6761\u4ef6\u7684\u7ed3\u679c", "search.result.none": "\u6ca1\u6709\u627e\u5230\u7b26\u5408\u6761\u4ef6\u7684\u7ed3\u679c", "search.result.one": "\u627e\u5230 1 \u4e2a\u7b26\u5408\u6761\u4ef6\u7684\u7ed3\u679c", "search.result.other": "# \u4e2a\u7b26\u5408\u6761\u4ef6\u7684\u7ed3\u679c", "search.result.placeholder": "\u952e\u5165\u4ee5\u5f00\u59cb\u641c\u7d22", "search.result.term.missing": "\u7f3a\u5c11", "select.version": "\u9009\u62e9\u5f53\u524d\u7248\u672c"}}</script>
    
    
      <script src="../../../assets/javascripts/bundle.aecac24b.min.js"></script>
      
        <script src="../../../javascripts/mathjax.js"></script>
      
        <script src="https://polyfill.io/v3/polyfill.min.js?features=es6"></script>
      
        <script src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script>
      
    
  </body>
</html>